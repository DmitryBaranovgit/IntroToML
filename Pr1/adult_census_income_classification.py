# -*- coding: utf-8 -*-
"""ML. Practice 1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PiDcNmf7eoFC4BaCEwuvwoGWsyTAN20i

# Практическая работа
Баранов Д.А. ИВТ 2.1

# Предсказание уровня дохода по данным переписи населения США
### Датасет Adult Census Income

# 2. Оглавление

## Содержание
1. [Описание задачи](#Описание-задачи)
2. [Загрузка данных](#Загрузка-данных)
3. [Предварительный анализ (EDA)](#Предварительный-анализ)
4. [Предобработка данных](#Предобработка-данных)
5. [Разделение на выборки](#Разделение-на-выборки)
6. [Обучение моделей](#Обучение-моделей)
7. [Сравнение моделей](#Сравнение-моделей)
8. [Сохранение лучшей модели](#Сохранение-модели)

# 1. Описание задачи
Целью проекта является построение модели, способной предсказать, имеет ли человек доход более 50 000 долларов в год, основываясь на социально-демографических данных из переписи населения США 1994.

# 2. Загрузка данных

1. Разархивировать и изучить данные
"""

import pandas as pd
import zipfile

with zipfile.ZipFile('/content/adult.zip', 'r') as zip_ref:
  zip_ref.extractall('/content/adult_dataset')

columns = [
    "age", "workclass", "fnlwgt", "education", "education-num",
    "marital-status", "occupation", "relationship", "race", "sex",
    "capital-gain", "capital-loss", "hours-per-week", "native-country", "income"
]

# Загрузка train-данных и проверка
df = pd.read_csv('/content/adult_dataset/adult.data', header = None, names = columns, na_values = ' ?', skipinitialspace= True)
df.head()

"""# 3. Предварительный анализ (EDA)"""

df.shape
df.dtypes
df.isnull().sum()
df['income'].value_counts(normalize = True)

import matplotlib.pyplot as plt
import seaborn as sns

sns.countplot(x = 'income', data = df)
plt.title("Распределение доходов")

# Boxpot по количественным признакам
df[['age', 'capital-gain', 'capital-loss', 'hours-per-week']].plot(kind='box', subplots=True, figsize=(10, 6))

"""# 4. Предобработка данных"""

# Удалим пропуски
df.dropna(inplace=True)

# Закодируем целевую переменную
from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
df['income'] = le.fit_transform(df['income']) # <=50K = 0, >50K = 1

"""Разделим признаки:"""

cat_cols = [col for col in df.select_dtypes(include='object').columns if col != 'income']
num_cols = [col for col in df.select_dtypes(exclude='object').columns if col != 'income']

print("cat_cols:", cat_cols)
print("num_cols:", num_cols)

"""# 5. Разделение на выборки"""

from sklearn.model_selection import train_test_split

X = df.drop('income', axis=1)
y = df['income']

X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size = 0.3, stratify = y, random_state = 42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size = 0.5, stratify = y_temp, random_state = 42)

print(df.columns)

"""# 6. Построение пайплайна обработки + моделей"""

from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier

# Преобразование данных
numeric_transformer = Pipeline(steps = [
    ('imputer', SimpleImputer(strategy = 'median')),
    ('scaler', StandardScaler())
])

categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy = 'most_frequent')),
    ('onehot', OneHotEncoder(handle_unknown = 'ignore'))
])

preprocessor = ColumnTransformer(transformers = [
    ('num', numeric_transformer, num_cols),
    ('cat', categorical_transformer, cat_cols)
])

"""Пример: Логистическая регрессия"""

clf = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', LogisticRegression(max_iter = 1000))
])

clf.fit(X_train, y_train)

"""# 7. Оценка качества модели"""

from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report

y_pred = clf.predict(X_val)
print(classification_report(y_val, y_pred))

"""# 8. Сравнение моделей"""

models = {
    'LogisticRegression': LogisticRegression(max_iter = 1000),
    'DecisionTree': DecisionTreeClassifier(),
    'RandomForest': RandomForestClassifier()
}

for name, model in models.items():
  pipe = Pipeline([
      ('preprocessor', preprocessor),
      ('classifier', model)
  ])
  pipe.fit(X_train, y_train)
  preds = pipe.predict(X_val)
  acc = accuracy_score(y_val, preds)
  print(f"{name}: Accuracy = {acc:.4f}")

"""# 9. Сохранение модели"""

import joblib

final_model = Pipeline([
    ('preprocessor', preprocessor),
    ('classifier', RandomForestClassifier())
])

final_model.fit(X_train, y_train)
joblib.dump(final_model, 'model.pkl')

"""# 10. Заключение

## Заключение
Проведен полный цикл анализа данных: от загрузки и предобработки до обучения и сохранения финальной модели. Модель может быть использована в виде сервиса для предсказания уровня дохода на основе новых данных.

# Продвинутые модели: XGBoost, CatBoost, SVM, MLP
"""

!pip install xgboost catboost scikit-learn

from xgboost import XGBClassifier
from catboost import CatBoostClassifier
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier

advanced_models = {
    "XGBoost": XGBClassifier(use_label_encoder = False, eval_metric = 'logloss'),
    "CatBoost": CatBoostClassifier(verbose = 0),
    "SVM": SVC(probability = True),
    "MLP": MLPClassifier(max_iter = 300)
}

for name, model in advanced_models.items():
  pipe = Pipeline([
      ('preprocessor', preprocessor),
      ('model', model)
  ])
  pipe.fit(X_train, y_train)
  y_pred = pipe.predict(X_val)
  print(f"{name}: Accuracy = {accuracy_score(y_val, y_pred):.4f}, F1 = {f1_score(y_val, y_pred):.4f}")

"""# Загрузка модели на Kaggle"""

!pip install -q kaggle

"""# Загрузка токена **kaggle.json** в Colab"""

import os
os.environ['KAGGLE_CONFIG_DIR'] = '/root/.config/kaggle'

!mkdir -p /root/.config/kaggle
!mkdir -p /content/output_dir

!cp kaggle.json /root/.config/kaggle/
!chmod 600 /root/.config/kaggle/kaggle.json

!kaggle --version
!ls -l /root/.config/kaggle/kaggle.json

"""# Загрузка модели"""

!cp -r /content/model.pkl /content/output_dir
!kaggle datasets init -p /content/output_dir

from google.colab import files
files.view('/content/output_dir/dataset-metadata.json')

!kaggle datasets create -p /content/output_dir

"""# ROC-кривая, PR-кривая, SHAP, LIME"""

from sklearn.metrics import roc_curve, auc, precision_recall_curve

y_proba = final_model.predict_proba(X_test)[:, 1]
fpr, tpr, _ = roc_curve(y_test, y_proba)
precision, recall, _ = precision_recall_curve(y_test, y_proba)

plt.plot(fpr, tpr, label=f'ROC AUC = {auc(fpr, tpr):.2f}')
plt.xlabel('FPR'); plt.ylabel('TPR'); plt.title('ROC-кривая')
plt.legend(); plt.grid(); plt.show()

plt.plot(recall, precision, label = 'PR-кривая')
plt.xlabel('Recall'); plt.ylabel('Precision'); plt.grid()
plt.legend(); plt.title('PR-кривая'); plt.show()

"""# SHAP:"""

print(final_model.named_steps.keys())

!pip install shap

import shap
import numpy as np

ohe = preprocessor.named_transformers_['cat']['onehot']
ohe_feature_names = ohe.get_feature_names_out(cat_cols)
all_feature_names = np.concatenate([num_cols, ohe_feature_names])

X_test_transformed = preprocessor.transform(X_test)

if hasattr(X_test_transformed, "toarray"):
  X_test_transformed_df = pd.DataFrame(X_test_transformed.toarray(), columns=all_feature_names)
else:
  X_test_transformed_df = pd.DataFrame(X_test_transformed, columns=all_feature_names)

model = final_model.named_steps['classifier']

explainer = shap.Explainer(model, X_test_transformed_df)

shap_values = explainer(X_test_transformed_df)

shap.plots.beeswarm(shap_values)

"""# Логистическая регрессия

Модель предсказывает вероятность принадлжености к классу `1` по формуле:

$$
P(y=1|x) = \\frac{1}{1 + e^{-z}}, \\text{ где } z = w_0 + w_1 x_1 + w_2 x_2 + ... + w_n x_n
$$

Где:
- $x_i$ - входные признаки
- $w_i$ - веса
- $z$ - линейная комбинация признаков

"""